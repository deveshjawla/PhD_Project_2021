using Distributions

d = 2;
n = 100;

observations = randn((d, n)); # 100 observations from 2D ğ’©(0, 1)

# Define generative model
#    Î¼ ~ ğ’©(0, 1)
#    xáµ¢ âˆ¼ ğ’©(Î¼, 1) , âˆ€i = 1, â€¦, n
prior(Î¼) = logpdf(MvNormal(ones(d)), Î¼)

likelihood(x, Î¼) = sum(logpdf(MvNormal(Î¼, ones(d)), x))

logÏ€(Î¼) = likelihood(observations, Î¼) + prior(Î¼)

logÏ€(randn(2))  # <= just checking that it works

using DistributionsAD, AdvancedVI

# Using a function z â†¦ q(â‹…âˆ£z)
getq(Î¸) = TuringDiagMvNormal(Î¸[1:d], exp.(Î¸[d+1:4]))

# Perform VI
advi = ADVI(10, 10_000)

q = vi(logÏ€, advi, getq, randn(4))
AdvancedVI.elbo(advi, q, logÏ€, 1000)

# True posterior
using ConjugatePriors

pri = MvNormal(zeros(2), ones(2));

true_posterior = posterior((pri, pri.Î£), MvNormal, observations)

using Plots

p_samples = rand(true_posterior, 10_000);
q_samples = rand(q, 10_000);

p1 = histogram(p_samples[1, :], label = "p");
histogram!(q_samples[1, :], alpha = 0.7, label = "q");

title!(raw"$\mu_1$")

p2 = histogram(p_samples[2, :], label = "p");
histogram!(q_samples[2, :], alpha = 0.7, label = "q");

title!(raw"$\mu_2$")

plot(p1, p2)
